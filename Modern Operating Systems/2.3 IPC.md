## InterProcess Communication

In IPC there are 3 issues: 
* how can one process pass information to another
* how to make sure two processes do not get into each other way
* proper sequencing when dependencies are present

### Race Conditions

In order to avoid race conditions we need **mutual exclusion**.

The part of the program where the shared memory is accessed is called *critical region* or *critical section*. A requirement to avoid race conditions is that no two processes are in their critical region at the same time. However this condition itself is not sufficient for having parallel processes cooperate correctly and efficiently. We need the following:

1. No two processes may be simultaneously inside their critical regions
2. No assumption may be made about speeds or the number of CPUs
3. No process running outside its critical region may block any process 
4. No process should have to wait forever to enter its critical region

#### Mutual exclusion by busy waiting

**Disable interrupts**

On a single processor system the easiest solution is to have each process disable all interrupts after entering its critical region and re-enable them just before leaving it.

This approach is unattractive since it is unwise to give user processes the power to turn off interrupts. What if one process does not turn them on? It would be the end of the system.

**Lock variables**

We could consider a shared (lock) variable set to 0. If the lock is 0 the process sets it to 1 and enters its critical region. If the lock is already 1 the process waits until it becomes 0.

Unfortunately there is a flaw: suppose one process reads the lock and sees it is 0. Before it can set the lock to 1 another process is scheduled, runs and sets the lock to 1.

**Strict alternation**

```
while (TRUE) {
	while (turn != 0) critical_region();

	turn = 1;
	noncritical_region();
}
```

Continuously testing a variable until some value appears is called **busy waiting**. It should be avoided since it wastes CPU time.
A lock that uses busy waiting is called a **spin lock**.

Taking turns is not a good idea when one of the two processes is much slower than the other.

This situation violates condition 3 set above.

**Peterson's solution**

```
#define FALSE 0
#define TRUE  1
#define N	  2

int turn;
int interested[N];

void enter_region(int process) {
	int other;
	other = 1-process;
	interested[process] = TRUE;
	turn = process;
	while (turn == process && interested[other] == TRUE) /* null statement */ ;
}

void leave_region(int process) {
	interested[process] = FALSE;
}
```
Before using the shared variables (eg. before entering its critical region) each process calles `enter_region` with its own process number as parameter. This call will cause it to wait until it is safe to enter.

**The TSL instruction**

`TSL RX, LOCK`

The TSL (Test and Set Lock) instruction works as follows: it reads the content of the memory word *lock* into register `RX` and then stores a non zero value at the memory address lock. The operations of reading the word and storing into it are **guaranteed to be indivisible**. 

It is important to note that locking the memory bus is very different from disabling the interrupts. Disabling interrupts then performing a read on memory word followed by a write does not prevent a second processor on the bus from accessing the word between the read and write. In fact disabling interrupts on processor 1 has no effect at all on processor 2.

```
enter_region:
	TSL REGISTER,LOCK		// copy lock to register and set lock to 1
	CMP REGISTER,#0			// was lock zero?
	JNE enter_region		// if it was not zero lock was set, so loop
	RET

leave_region:
	MOVE LOCK,#0
	RET
```

An alternative instruction to TSL is XCHG which exchanges the content of two locations atomically.

### Sleep and Wakeup

Both Peterson's solution and the ones using TSL or XCHG are correct, but both have the defect of requiring busy waiting. In essence what these solutions do is this: when a process wants to enter its critical region, it checks to see if the entry is allowed. If it is not the process just sits in a tight loop waiting until it is.

Not only this approach wastes CPU time but also leads to unexpected results. Let us have two processes H and L, with high and low priorities respectively. When L is in its critical region, H becomes ready to run. H begins busy waiting but since L is never scheduled while H is running, L never gets a chance to leave its critical region, so H loops forever. This is sometimes referred to as the **priority inversion problem**.

**The produced consumer problem**

Two processes shared a common, fixed size buffer. One of the them, the producer, puts information inside the buffer, and the other one, the consumer, takes it out.

Trouble arises when the consumer wants to insert a new item in the buffer but it is already full or when the consumer wants to retrive an item but the buffer is empty. The solution is for the producer to go to sleep and be awakened when the consumer has removed at least one item and for the consumer to go to sleep until the producer has put a new item in the buffer.

This approach is simple but incurs in a race condition. We need a variable *count* to keep track of the number of items in the buffer.

```
#define N 100
int count = 0;

void producer(void)
{
	int item;

	while (TRUE)
	{
		item = produce_new_item();
		if (count == N) sleep();
		insert_item(item);
		count = count +1;
		if (count == 1) wakeup(consumer);
	}
}

void consumer(void)
{
	int item;

	while (TRUE)
	{
		if (count == 0) sleep();
		item = remove_item();
		count = count-1;
		if (count == N-1) wakeup(producer);
		consumer_item(item);
	}
}
```

It could happen that the consumer has just read *count* to see if it is 0.
The scheduler stops the consumer temporarily and start running the producer. The producer inserts an element and increment *count* which now is 1 and thus sends a *wakeup* to the consumer.
Since the consumer is not logically asleep the *wakeup* is lost. When the consumer next runs it tests the value of *count* previously read, find it to be 0 and goes to sleep. Sooner or later the producer will fill the buffer and go to sleep. Both will sleep forever.

The essence of the problem is that *a wakeup that is sent to a non sleeping process is lost*.

A quick fix is to add a wakeup waiting bit to the picture. It saves the day but becomes insufficient with more complex examples.

### Semaphores

Dijkstra suggested using an integer variable, called **semaphore**, to count the number of wakeups saved for future use.

There are two operations on semaphores: *up* and *down*. *down* checks if the value of the semaphore is greater than 0. If so it decrements the value. If the value is 0 the process is put to sleep without completing the down.

Checking the value, changing it and possibly going to sleep are all done as a **single indivisible atomic action**.

The *up* operation increments the value of the semaphore addressed. If one or more processes were sleeping on that semaphore, unable to complete an earlier *down*, one of them is chosen by the system and is allowed to complete its *down*.

#### Solving the producer-consumer problem with semaphores

```
#define N 100
typedef int semaphore;
semaphore mutex = 1; // make sure the producer and the consumer do not access the buffer at the same time
semaphore empty = N; // number of slots that are empty
semaphore full = 0;  // number of slots that are full

void producer(void)
{
	int item;

	while (TRUE)
	{
		item = produce_new_item();
		down(&empty);				// decrement empty count
		down(&mutex);				// enter critical region
		insert_item(item);
		up(&mutex);					// leave critical region
		up(&full);					// increment count of full slots
	}
}

void consumer(void)
{
	int item;

	while (TRUE)
	{
		down(&full);
		down(&mutex);
		item = remove_item();
		up(&mutex);
		up(&empty);
		consume_item(item);
	}
}
```

**Remark.** The *mutex* semaphore is used for **mutual exclusion**. It is designed to guarantee that only a process at time will write or read a certain buffer. The *full* and *empty* semaphores are used for **synchronization**, they guarantee that certain event sequences do or do not occurr.

### Mutexes

When the semaphore's ability to count is not needed, a simplified version of the semaphore, called mutex, is used.
Mutexes are used for managing mutual exclusion to some shared resources or piece of code.

A mutex is a shared variable that can be only in two states: lock or unlocked.